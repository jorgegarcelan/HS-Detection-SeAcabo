{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add context to models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, DistilBertTokenizer, BertModel, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup, RobertaTokenizer, RobertaModel, XLMRobertaModel, AutoTokenizer, AutoModelForSequenceClassification, XLMRobertaForSequenceClassification, RobertaForSequenceClassification\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import string\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "\n",
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import time\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_embedding_to_list(list_embedding):\n",
    "    num_list = ast.literal_eval(list_embedding)\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_name, embedding_name):\n",
    "    # OpenAI Embedding\n",
    "    if embedding_name == \"text-embedding-3-large\":\n",
    "        df = pd.read_csv('C:/Users/jorge/Desktop/UNI/4-CUARTO/4-2-TFG/CODE/Gender-Bias/OpenAI/seacabo_embeddings.csv')\n",
    "        df['embeddings'] = df['embeddings'].apply(lambda x : convert_embedding_to_list(x))\n",
    "    else:\n",
    "        df = pd.read_csv(dataset_name)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_lang(df):\n",
    "    langs = ['es', 'cy', 'ht', 'in', 'lt', 'qam', 'tl', 'und']\n",
    "    df = df[df['lang'].isin(langs)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lexicon(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lexicon = {line.strip().lower() for line in file if line.strip()}\n",
    "    return lexicon\n",
    "\n",
    "def add_special_tokens(df, NEW_TOKENS):\n",
    "    # lexicons\n",
    "    misogyny_list = load_lexicon(\"../Lexicons/lexicons_train_misogyny_lexicon.txt\")\n",
    "    insults_list = load_lexicon(\"../Lexicons/lexicons_train_insults_lexicon.txt\")\n",
    "    victim_list = load_lexicon(\"../Lexicons/lexicons_victim_seacabo.txt\")\n",
    "    aggressor_list = load_lexicon(\"../Lexicons/lexicons_aggressor_seacabo.txt\")\n",
    "\n",
    "    def replace_words_with_tokens(text):\n",
    "        words = text.split()\n",
    "        processed_words = []\n",
    "        for word in words:\n",
    "            word_lower = word.lower()\n",
    "            if word_lower in insults_list or word_lower in misogyny_list:\n",
    "                processed_words.append(NEW_TOKENS[0]) # [INSULT]\n",
    "            elif word_lower in victim_list:\n",
    "                processed_words.append(NEW_TOKENS[1]) # [VICTIM]\n",
    "            elif word_lower in aggressor_list:\n",
    "                processed_words.append(NEW_TOKENS[2]) # [AGGRESSOR]\n",
    "            else:\n",
    "                processed_words.append(word)\n",
    "        return ' '.join(processed_words)\n",
    "    \n",
    "    # Aplicar la función de procesamiento a la columna especificada\n",
    "    df['full_text'] = df['full_text'].apply(replace_words_with_tokens)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(df, context, tweet_original):\n",
    "\n",
    "    # Preprocesado de datos\n",
    "    df['tweet_respuesta'] = df['full_text'].apply(lambda x: preprocess_tweet(x, lang=\"es\"))\n",
    "\n",
    "    # Añadir columnas para diferentes contextos:\n",
    "    df['Sin_contexto'] = df['tweet_respuesta'] # cambio full_text por tweet_respuesta\n",
    "    #df['Tweet_context'] = tweet_original + \" [SEP] \" + df['tweet_respuesta']\n",
    "    df['Full_context'] = tweet_original + \" [SEP] \" + df['tweet_respuesta'] + \" [SEP] \" + context\n",
    "    df['Tweet_context'] = tweet_original + \" [SEP] \" + df['tweet_respuesta']\n",
    "    #df['Full_context'] = df['tweet_respuesta'] + \" [SEP] \" + context\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_type(df, label_column):\n",
    "\n",
    "    if label_column == \"Análisis General\":\n",
    "        # Define the specific labels to keep\n",
    "        #etiquetas = [\"Comentario Positivo\", \"Comentario Negativo\", \"Comentario Neutro\"]\n",
    "        etiquetas = [\"Comentario Positivo\", \"Comentario Negativo\"]\n",
    "        \n",
    "        df['Análisis General'] = df['Análisis General'].where(df['Análisis General'].isin(etiquetas))\n",
    "\n",
    "\n",
    "        # Remove NAs\n",
    "        df = df.dropna(subset=['Análisis General'])\n",
    "        \n",
    "\n",
    "        # Factorize the 'Análisis General' column\n",
    "        labels, labels_names = pd.factorize(df['Análisis General'])\n",
    "\n",
    "        # 'labels' now contains the numeric representation of your original labels\n",
    "        # 'label_names' contains the unique values from your original column in the order they were encoded\n",
    "\n",
    "        # Replace the original column with the numeric labels\n",
    "        df['Análisis General'] = labels\n",
    "\n",
    "        # If you want to keep a record of the mapping from the original labels to the numeric labels\n",
    "        label_mapping = dict(zip(labels_names, range(len(labels_names))))\n",
    "        print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "    if label_column == \"Contenido Negativo\":\n",
    "\n",
    "        # Filtrar el DataFrame para seleccionar solo los \"Comentario Negativo\"\n",
    "        df = df.loc[df['Análisis General'] == 'Comentario Negativo']\n",
    "\n",
    "        # Define the specific labels to keep\n",
    "        etiquetas = [\"Desprestigiar Víctima\", \"Desprestigiar Acto\", \"Insultos\", \"Desprestigiar Deportista Autora\"]\n",
    "        df['Contenido Negativo'] = df['Contenido Negativo'].where(df['Contenido Negativo'].isin(etiquetas))\n",
    "\n",
    "        # Remove NAs\n",
    "        df = df.dropna(subset=['Contenido Negativo'])\n",
    "        \n",
    "\n",
    "        # Factorize the 'Análisis General' column\n",
    "        labels, labels_names = pd.factorize(df['Contenido Negativo'])\n",
    "\n",
    "        # 'labels' now contains the numeric representation of your original labels\n",
    "        # 'label_names' contains the unique values from your original column in the order they were encoded\n",
    "\n",
    "        # Replace the original column with the numeric labels\n",
    "        df['Contenido Negativo'] = labels\n",
    "\n",
    "        # If you want to keep a record of the mapping from the original labels to the numeric labels\n",
    "        label_mapping = dict(zip(labels_names, range(len(labels_names))))\n",
    "        print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "\n",
    "    if label_column == \"Insultos\":\n",
    "\n",
    "        # Filtrar el DataFrame para seleccionar solo los \"Comentario Negativo\"\n",
    "        df = df.loc[df['Análisis General'] == 'Comentario Negativo']\n",
    "\n",
    "        # Filtrar el DataFrame para seleccionar solo los \"Insultos\" no vacíos\n",
    "        df = df.loc[df['Insultos'].notna() & (df['Insultos'].str.strip() != '')]\n",
    "\n",
    "        # Define the specific labels to keep\n",
    "        etiquetas = [\"Deseo de Dañar\", \"Genéricos\", \"Sexistas/misóginos\"]\n",
    "\n",
    "        # Replace labels that are not in the list with \"Genéricos\"\n",
    "        df['Insultos'] = df['Insultos'].where(df['Insultos'].isin(etiquetas), other=\"Genéricos\")\n",
    "\n",
    "        # Remove NAs\n",
    "        df = df.dropna(subset=['Insultos'])\n",
    "        \n",
    "\n",
    "        # Factorize the 'Insultos' column\n",
    "        labels, labels_names = pd.factorize(df['Insultos'])\n",
    "\n",
    "        # 'labels' now contains the numeric representation of your original labels\n",
    "        # 'label_names' contains the unique values from your original column in the order they were encoded\n",
    "\n",
    "        # Replace the original column with the numeric labels\n",
    "        df['Insultos'] = labels\n",
    "\n",
    "        # If you want to keep a record of the mapping from the original labels to the numeric labels\n",
    "        label_mapping = dict(zip(labels_names, range(len(labels_names))))\n",
    "        print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "    num_labels = len(etiquetas)\n",
    "\n",
    "\n",
    "\n",
    "    return df, labels_names, num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer(name):\n",
    "    \n",
    "    if name == \"dccuchile/bert-base-spanish-wwm-cased\":\n",
    "        tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
    "\n",
    "    if name == \"PlanTL-GOB-ES/roberta-large-bne\":\n",
    "        tokenizer = RobertaTokenizer.from_pretrained('PlanTL-GOB-ES/roberta-large-bne') \n",
    "\n",
    "    if name == \"bert-base-multilingual-cased\":\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "    if name == \"FacebookAI/xlm-roberta-base\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
    "\n",
    "    if name == \"pysentimiento/robertuito-base-cased\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained('pysentimiento/robertuito-base-cased')\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar inputs tokenizados para cada contexto\n",
    "def prepare_inputs(df, text_column, label_column, tokenizer):\n",
    "    \n",
    "    # Tokenización de los textos\n",
    "    tokenized_data = tokenizer(df[text_column].tolist(), padding=PADDING, truncation=TRUNCATION, max_length=MAX_LENGTH, return_tensors='pt')\n",
    "    \n",
    "    # Factorizar las etiquetas si son categóricas\n",
    "    labels, _ = pd.factorize(df[label_column])\n",
    "    \n",
    "    # Convertir las etiquetas a un tensor\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    # Retorna un diccionario con los inputs tokenizados y las etiquetas\n",
    "    return {**tokenized_data, 'labels': labels}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hf_dataset(tokenized_inputs):\n",
    "    return Dataset.from_dict(tokenized_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para dividir un dataset en train, validation y test\n",
    "def split_dataset(dataset, test_size=0.1, val_size=0.3):\n",
    "    # Dividir primero en train+val y test\n",
    "    train_val_dataset, test_dataset = dataset.train_test_split(test_size=test_size).values()\n",
    "\n",
    "    # Ahora dividir train+val en train y val\n",
    "    train_dataset, val_dataset = train_val_dataset.train_test_split(test_size=val_size / (1 - test_size)).values()\n",
    "\n",
    "    return DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'validation': val_dataset,\n",
    "        'test': test_dataset\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_train_test_val_split(dataset, test_size, val_size, seed=0):\n",
    "    # Convertir a pandas DataFrame para usar la funcionalidad de scikit-learn\n",
    "    df = dataset.to_pandas()\n",
    "    \n",
    "    # Estratificar y dividir el conjunto de datos en entrenamiento+validación y test\n",
    "    train_val_df, test_df = train_test_split(df, test_size=test_size, stratify=df['labels'], random_state=seed)\n",
    "    \n",
    "    # Estratificar y dividir el conjunto de entrenamiento+validación en entrenamiento y validación\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=val_size/(1.0-test_size), stratify=train_val_df['labels'], random_state=seed)\n",
    "    \n",
    "    # Convertir de nuevo a datasets de HuggingFace\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    val_dataset = Dataset.from_pandas(val_df)\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "    \n",
    "    # Crear un DatasetDict\n",
    "    split_dataset = DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'validation': val_dataset,\n",
    "        'test': test_dataset\n",
    "    })\n",
    "    \n",
    "    # Calcular el número de ejemplos por clase en cada subconjunto\n",
    "    train_class_counts = Counter(train_df['labels'])\n",
    "    val_class_counts = Counter(val_df['labels'])\n",
    "    test_class_counts = Counter(test_df['labels'])\n",
    "\n",
    "    # Retornar el DatasetDict y las cuentas de clases\n",
    "    return split_dataset, {'train': train_class_counts, 'validation': val_class_counts, 'test': test_class_counts}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(name, num_labels):\n",
    "    if name == \"dccuchile/bert-base-spanish-wwm-cased\":\n",
    "        model = BertForSequenceClassification.from_pretrained(name, num_labels=num_labels)\n",
    "\n",
    "    if name == \"PlanTL-GOB-ES/roberta-large-bne\":\n",
    "        model = RobertaForSequenceClassification.from_pretrained(name, num_labels=num_labels) \n",
    "\n",
    "    if name == \"bert-base-multilingual-cased\":\n",
    "        model = BertForSequenceClassification.from_pretrained(name, num_labels=num_labels)\n",
    "\n",
    "    if name == \"FacebookAI/xlm-roberta-base\":\n",
    "        model = XLMRobertaForSequenceClassification.from_pretrained(name, num_labels=num_labels)\n",
    "\n",
    "    if name == \"pysentimiento/robertuito-base-cased\":\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(name, num_labels=num_labels)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Obtener reporte completo\n",
    "    report = classification_report(labels, predictions, output_dict=True)\n",
    "    \n",
    "    # Obtener la matriz de confusión\n",
    "    conf_matrix = confusion_matrix(labels, predictions)\n",
    "    \n",
    "    # Extraer métricas para cada clase y globales\n",
    "    metrics = {\n",
    "        'accuracy': report['accuracy'],\n",
    "        'weighted_f1': report['weighted avg']['f1-score'],\n",
    "        'weighted_precision': report['weighted avg']['precision'],\n",
    "        'weighted_recall': report['weighted avg']['recall'],\n",
    "        # La matriz de confusión no se incluye normalmente como una métrica devuelta porque no es un escalar\n",
    "        'confusion_matrix': conf_matrix.tolist()  # Convertir a lista para asegurarse de que es serializable si es necesario\n",
    "    }\n",
    "    \n",
    "    # Añadir métricas específicas por clase si se requiere\n",
    "    for label, scores in report.items():\n",
    "        if label not in [\"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
    "            metrics[f'{label}_precision'] = scores['precision']\n",
    "            metrics[f'{label}_recall'] = scores['recall']\n",
    "            metrics[f'{label}_f1'] = scores['f1-score']\n",
    "            metrics[f'{label}_support'] = scores['support']\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_args(context_type, learning_rate_scheduler_type=\"linear\", num_train_epochs=3, per_device_train_batch_size=16, per_device_eval_batch_size=16, warmup_steps=500, weight_decay=0.01, logging_steps=10):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'./results/{context_type}',\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "        warmup_steps=warmup_steps,\n",
    "        weight_decay=weight_decay,\n",
    "        logging_dir=f'./logs/{context_type}',\n",
    "        logging_steps=logging_steps,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        #save_strategy=\"epoch\",\n",
    "        #load_best_model_at_end=True\n",
    "        save_strategy=\"no\",  # No guardar modelos\n",
    "        save_total_limit=0,  # No mantener checkpoints\n",
    "        metric_for_best_model=\"eval_f1\",\n",
    "        load_best_model_at_end=False,  # No cargar el mejor modelo al final del entrenamiento\n",
    "    )\n",
    "\n",
    "    return training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveResultsCallback(TrainerCallback):\n",
    "    def __init__(self, excel_path, training_args, run_id, additional_info, type_d, num_labels):\n",
    "        self.excel_path = excel_path\n",
    "        self.training_args = vars(training_args)  # Convert training arguments to dictionary\n",
    "        self.run_id = run_id\n",
    "        self.additional_info = additional_info  # Assumed to be a dictionary\n",
    "        self.type_d = type_d  # Type of dataset or context\n",
    "        self.rows = []\n",
    "        self.initialized = False\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "    def on_train_begin(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        if state.is_local_process_zero:\n",
    "            if not self.initialized:\n",
    "                self.init_excel()\n",
    "                self.initialized = True\n",
    "\n",
    "    def init_excel(self):\n",
    "        # Initialize the Excel file with proper headers if it does not exist\n",
    "        if not Path(self.excel_path).exists():\n",
    "            with pd.ExcelWriter(self.excel_path, engine='openpyxl') as writer:\n",
    "                # Inicializar los encabezados dinámicamente basados en el número de clases\n",
    "                metric_headers = ['eval_loss', 'eval_accuracy', 'eval_weighted_f1', 'eval_weighted_precision', 'eval_weighted_recall']\n",
    "                metric_headers.append('eval_confusion_matrix')\n",
    "                # Agregar encabezados de métricas para cada clase\n",
    "                for i in range(self.num_labels):\n",
    "                    metric_headers.extend([\n",
    "                        f'eval_{i}_precision',\n",
    "                        f'eval_{i}_recall',\n",
    "                        f'eval_{i}_f1',\n",
    "                        f'eval_{i}_support'\n",
    "                    ])\n",
    "                \n",
    "                metric_headers.append('eval_runtime')\n",
    "                metric_headers.append('eval_samples_per_second')\n",
    "                metric_headers.append('eval_steps_per_second')\n",
    "\n",
    "                # Definir encabezados para la creación del archivo Excel\n",
    "                headers = [\"run_id\", \"type_d\", *self.additional_info.keys(), \"epoch\", *metric_headers, *self.training_args.keys()]\n",
    "                df_header = pd.DataFrame(columns=headers)\n",
    "                df_header.to_excel(writer, sheet_name=self.type_d, index=False)\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, metrics, **kwargs):\n",
    "        if state.is_local_process_zero:\n",
    "            # Prepare data dictionary for the current epoch\n",
    "            data = {\"run_id\": self.run_id, \"type_d\": self.type_d, **self.additional_info, \"epoch\": state.epoch, **metrics, **self.training_args}\n",
    "            self.rows.append(data)\n",
    "\n",
    "    def on_train_end(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        if state.is_local_process_zero:\n",
    "            self.save_to_excel()\n",
    "\n",
    "    def save_to_excel(self):\n",
    "        # Save collected data to Excel, appending to the existing sheet or creating it if not exists\n",
    "        with pd.ExcelWriter(self.excel_path, mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:\n",
    "            df = pd.DataFrame(self.rows)\n",
    "            start_row = writer.sheets[self.type_d].max_row if self.type_d in writer.book.sheetnames else 0\n",
    "            df.to_excel(writer, sheet_name=self.type_d, index=False, header=not bool(start_row), startrow=start_row)\n",
    "            print(f\"Data logged to {self.excel_path} in sheet {self.type_d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_data(excel_path, run_id, eval_results, training_args, additional_info, type_d):\n",
    "    # Define el nombre de la hoja basado en el tipo de dataset\n",
    "    sheet_name = f\"{type_d}\"\n",
    "\n",
    "    # Crear el archivo Excel si no existe\n",
    "    if not Path(excel_path).exists():\n",
    "        # Si el archivo no existe, crearlo con una hoja dummy para inicializarlo\n",
    "        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "            pd.DataFrame().to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "\n",
    "    # Cargar o inicializar el DataFrame dependiendo de la existencia de la hoja\n",
    "    if sheet_name in pd.ExcelFile(excel_path).sheet_names:\n",
    "        df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "    # Convertir el objeto de argumentos de entrenamiento a diccionario si es necesario\n",
    "    training_args_dict = vars(training_args) if not isinstance(training_args, dict) else training_args\n",
    "\n",
    "    # Asegurarte de que los resultados de evaluación son un diccionario\n",
    "    eval_results_dict = eval_results if isinstance(eval_results, dict) else vars(eval_results)\n",
    "\n",
    "    # Construir la fila de datos a agregar\n",
    "    data = {\n",
    "        **{'Run_ID': run_id},\n",
    "        **training_args_dict,\n",
    "        **eval_results_dict,\n",
    "        **additional_info\n",
    "    }\n",
    "\n",
    "    # Convertir todos los valores a strings si no son int, float o string\n",
    "    for key, value in data.items():\n",
    "        if not isinstance(value, (int, float, str)):\n",
    "            data[key] = str(value)\n",
    "\n",
    "    # Agregar la nueva fila al DataFrame\n",
    "    df = df._append(data, ignore_index=True)\n",
    "\n",
    "    # Guardar el DataFrame en la hoja correspondiente\n",
    "    with pd.ExcelWriter(excel_path, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(f\"Data logged to {excel_path} in sheet {sheet_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'Sexistas/misóginos': 0, 'Genéricos': 1, 'Deseo de Dañar': 2}\n",
      "3\n",
      "----------\n",
      "type_d='Sin_contexto'\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 93\u001b[0m\n\u001b[0;32m     85\u001b[0m additional_info \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel_Description\u001b[39m\u001b[38;5;124m'\u001b[39m: MODEL_NAME,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData_File\u001b[39m\u001b[38;5;124m'\u001b[39m: DATA,\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m: type_d,\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass_Counts\u001b[39m\u001b[38;5;124m'\u001b[39m: class_counts,\n\u001b[0;32m     90\u001b[0m }\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m model\u001b[38;5;241m.\u001b[39mresize_token_embeddings(\u001b[38;5;28mlen\u001b[39m(tokenizer))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[49], line 6\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, num_labels)\u001b[0m\n\u001b[0;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m BertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(name, num_labels\u001b[38;5;241m=\u001b[39mnum_labels)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlanTL-GOB-ES/roberta-large-bne\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 6\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mRobertaForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-multilingual-cased\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      9\u001b[0m     model \u001b[38;5;241m=\u001b[39m BertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(name, num_labels\u001b[38;5;241m=\u001b[39mnum_labels)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:3502\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3494\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   3495\u001b[0m     (\n\u001b[0;32m   3496\u001b[0m         model,\n\u001b[0;32m   3497\u001b[0m         missing_keys,\n\u001b[0;32m   3498\u001b[0m         unexpected_keys,\n\u001b[0;32m   3499\u001b[0m         mismatched_keys,\n\u001b[0;32m   3500\u001b[0m         offload_index,\n\u001b[0;32m   3501\u001b[0m         error_msgs,\n\u001b[1;32m-> 3502\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   3506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3509\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3510\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3513\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3514\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3518\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3520\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[0;32m   3521\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:3869\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m   3859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3860\u001b[0m     \u001b[38;5;66;03m# Whole checkpoint\u001b[39;00m\n\u001b[0;32m   3861\u001b[0m     mismatched_keys \u001b[38;5;241m=\u001b[39m _find_mismatched_keys(\n\u001b[0;32m   3862\u001b[0m         state_dict,\n\u001b[0;32m   3863\u001b[0m         model_state_dict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3867\u001b[0m         ignore_mismatched_sizes,\n\u001b[0;32m   3868\u001b[0m     )\n\u001b[1;32m-> 3869\u001b[0m     error_msgs \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3870\u001b[0m     offload_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3871\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3872\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n\u001b[0;32m   3873\u001b[0m \n\u001b[0;32m   3874\u001b[0m     \u001b[38;5;66;03m# This should always be a list but, just to be sure.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:626\u001b[0m, in \u001b[0;36m_load_state_dict_into_model\u001b[1;34m(model_to_load, state_dict, start_prefix)\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    624\u001b[0m             load(child, state_dict, prefix \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 626\u001b[0m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# Delete `state_dict` so it could be collected by GC earlier. Note that `state_dict` is a copy of the argument, so\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;66;03m# it's safe to delete it.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:624\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 624\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:624\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 624\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:624\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 624\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:620\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    618\u001b[0m                     module\u001b[38;5;241m.\u001b[39m_load_from_state_dict(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 620\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2040\u001b[0m, in \u001b[0;36mModule._load_from_state_dict\u001b[1;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[0;32m   2038\u001b[0m                 \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, input_param)\n\u001b[0;32m   2039\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2040\u001b[0m             \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m   2042\u001b[0m     error_msgs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhile copying the parameter named \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2043\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhose dimensions in the model are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2044\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhose dimensions in the checkpoint are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_param\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2045\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124man exception occurred : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;241m.\u001b[39margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2046\u001b[0m                       )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Data\n",
    "DATA = \"../data/BBDD_SeAcabo.csv\"\n",
    "\n",
    "# Target Column\n",
    "LABEL_COLUMN = \"Insultos\" # [\"Análisis General\", \"Contenido Negativo\", \"Insultos\"]\n",
    "\n",
    "# New Tokens\n",
    "NEW_TOKENS = [\"[INSULT]\", \"[VICTIM]\", \"[AGGRESSOR]\"]\n",
    "\n",
    "# Types Dataset\n",
    "TYPES_DATASET = [\"Sin_contexto\"] # [\"Sin_contexto\", \"Tweet_context\", \"Full_context\"]\n",
    "\n",
    "# Tweet original Alexia Putellas\n",
    "TWEET_ORIGINAL = \"Esto es inaceptable. Se acabó. Contigo compañera @Jennihermoso\"\n",
    "\n",
    "# Contexto\n",
    "CONTEXT =   \"\"\"\n",
    "            En agosto de 2023, tras la victoria de la Selección femenina de fútbol de España en la Copa Mundial Femenina de Fútbol de 2023, durante la celebración en la entrega de las medallas y tras abrazar efusivamente a varias jugadoras, Luis Rubiales besó en los labios a la centrocampista Jennifer Hermoso mientras sujetaba su cabeza con las manos. Hermoso lo denunció ante la Fiscalía por acoso sexual, coacciones y agresión sexual. La Fiscalía presentó una demanda contra Rubiales ante la Audiencia Nacional en Madrid\n",
    "            \"\"\"\n",
    "\n",
    "# Model\n",
    "MODEL_NAME = \"PlanTL-GOB-ES/roberta-large-bne\" #[\"dccuchile/bert-base-spanish-wwm-cased\", \"PlanTL-GOB-ES/roberta-large-bne\", \"bert-base-multilingual-cased\", \"FacebookAI/xlm-roberta-base\", \"pysentimiento/robertuito-base-cased\"]\n",
    "\n",
    "# Hyperparameters\n",
    "PADDING = True\n",
    "TRUNCATION = True\n",
    "MAX_LENGTH = 512\n",
    "NUM_TRAIN_EPOCHS = 10\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE = 16\n",
    "PER_DEVICE_EVAL_BATCH_SIZE = 8\n",
    "WARMUP_STEPS = 500\n",
    "WEIGHT_DECAY = 0.01\n",
    "LOGGING_STEPS = 10\n",
    "LEARNING_RATE_SCHEDULER_TYPE = \"cosine\" # \"linear\", \"cosine\"\n",
    "\n",
    "# EXCEL\n",
    "EXCEL_PATH = 'DL2'\n",
    "\n",
    "\n",
    "models = [MODEL_NAME]\n",
    "for model in models:\n",
    "\n",
    "    \n",
    "\n",
    "    # Load data\n",
    "    df = load_data(dataset_name=DATA, embedding_name=None)\n",
    "\n",
    "    # Filter by lang\n",
    "    df = filter_by_lang(df)\n",
    "\n",
    "    ## Add special tokens\n",
    "    df = add_special_tokens(df, NEW_TOKENS)\n",
    "\n",
    "    # Preprocess data\n",
    "    df = preprocess_function(df, context=CONTEXT, tweet_original=TWEET_ORIGINAL)\n",
    "\n",
    "    # Labels\n",
    "    df, labels_names, num_labels = filter_by_type(df, LABEL_COLUMN)\n",
    "    print(num_labels)\n",
    "\n",
    "    # Tokenizer\n",
    "    tokenizer = load_tokenizer(name=MODEL_NAME)\n",
    "    tokenizer.add_tokens(NEW_TOKENS)\n",
    "\n",
    "    for type_d in TYPES_DATASET:\n",
    "        print(\"-\"*10)\n",
    "        print(f\"{type_d=}\")\n",
    "        print(\"-\"*10)\n",
    "\n",
    "        start_time = time.time()\n",
    "        timestamp = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "\n",
    "        # Prepare input\n",
    "        inputs_dataset = prepare_inputs(df, text_column=type_d, label_column=LABEL_COLUMN, tokenizer=tokenizer)\n",
    "\n",
    "        # Create datasets\n",
    "        dataset = create_hf_dataset(inputs_dataset)\n",
    "\n",
    "        # Split dataset\n",
    "        dataset, class_counts = stratified_train_test_val_split(dataset, test_size=0.2, val_size=0.1)\n",
    "\n",
    "        # Información adicional para registrar\n",
    "        run_id = str(uuid.uuid4())\n",
    "        additional_info = {\n",
    "            'Model_Description': MODEL_NAME,\n",
    "            'Data_File': DATA,\n",
    "            'Type': type_d,\n",
    "            'Class_Counts': class_counts,\n",
    "        }\n",
    "        \n",
    "        # Load model\n",
    "        model = load_model(name=MODEL_NAME, num_labels=num_labels)\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "        # Train\n",
    "        training_args = load_training_args(context_type=type_d, num_train_epochs=NUM_TRAIN_EPOCHS, per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH_SIZE, per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH_SIZE, warmup_steps=WARMUP_STEPS, weight_decay=WEIGHT_DECAY, logging_steps=LOGGING_STEPS)\n",
    "\n",
    "        save_results_callback = SaveResultsCallback(f\"{EXCEL_PATH}_Training_{LABEL_COLUMN}.xlsx\", training_args, run_id, additional_info, type_d, num_labels)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset['train'],\n",
    "            eval_dataset=dataset['validation'],\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks=[save_results_callback]\n",
    "        )\n",
    "        trainer.train()\n",
    "\n",
    "        # Eval\n",
    "        eval_results = trainer.evaluate(dataset['test'])\n",
    "        results_df = pd.DataFrame([eval_results])\n",
    "\n",
    "        # Llamar a log_data para guardar los resultados y la configuración\n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        additional_info['Total Time'] = exec_time\n",
    "        additional_info['Timestamp'] = timestamp\n",
    "        log_data(f\"{EXCEL_PATH}_{LABEL_COLUMN}.xlsx\", run_id, eval_results, training_args, additional_info, type_d)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import Trainer\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n",
    "\n",
    "\n",
    "def load_embeddings(embeddings_path):\n",
    "    embeddings_df = pd.read_csv(embeddings_path)\n",
    "    embeddings_df['embeddings'] = embeddings_df['embeddings'].apply(lambda x: np.fromstring(x.strip('[]'), sep=' '))\n",
    "    return embeddings_df\n",
    "\n",
    "\n",
    "def prepare_inputs_openai(df, label_column):\n",
    "    \"\"\"\n",
    "    Prepare inputs from a DataFrame for training, validation, and testing.\n",
    "    Since we're using precomputed embeddings, this function will bypass tokenization.\n",
    "    \"\"\"\n",
    "    inputs = {\n",
    "        'input_ids': df['embeddings'].tolist(),\n",
    "        'labels': df[label_column].tolist()\n",
    "    }\n",
    "    return inputs\n",
    "\n",
    "# Path to your embeddings CSV file\n",
    "EMBEDDINGS_PATH = 'C:/Users/jorge/Desktop/UNI/4-CUARTO/4-2-TFG/CODE/Gender-Bias/OpenAI/seacabo_embeddings.csv'\n",
    "# Embedding name\n",
    "EMBEDDING_NAME = \"text-embedding-3-large\"\n",
    "\n",
    "# Load the embeddings\n",
    "embeddings_df = load_embeddings(EMBEDDINGS_PATH)\n",
    "\n",
    "# Configuration parameters\n",
    "DATA = \"../data/BBDD_SeAcabo.csv\"\n",
    "LABEL_COLUMN = 'Análisis General'\n",
    "NEW_TOKENS = [\"[INSULT]\", \"[VICTIM]\", \"[AGGRESSOR]\"]\n",
    "TYPES_DATASET = [\"Sin_contexto\", \"Tweet_context\", \"Full_context\"]\n",
    "TWEET_ORIGINAL = \"Esto es inaceptable. Se acabó. Contigo compañera @Jennihermoso\"\n",
    "CONTEXT = \"\"\"\n",
    "            En agosto de 2023, tras la victoria de la Selección femenina de fútbol de España en la Copa Mundial Femenina de Fútbol de 2023, durante la celebración en la entrega de las medallas y tras abrazar efusivamente a varias jugadoras, Luis Rubiales besó en los labios a la centrocampista Jennifer Hermoso mientras sujetaba su cabeza con las manos. Hermoso lo denunció ante la Fiscalía por acoso sexual, coacciones y agresión sexual. La Fiscalía presentó una demanda contra Rubiales ante la Audiencia Nacional en Madrid\n",
    "            \"\"\"\n",
    "MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-cased\" #[\"dccuchile/bert-base-spanish-wwm-cased\", \"PlanTL-GOB-ES/roberta-large-bne\", \"bert-base-multilingual-cased\", \"FacebookAI/xlm-roberta-base\", \"pysentimiento/robertuito-base-cased\"]\n",
    "\n",
    "# Hyperparameters\n",
    "PADDING = True\n",
    "TRUNCATION = True\n",
    "MAX_LENGTH = 512\n",
    "NUM_TRAIN_EPOCHS = 10\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE = 16\n",
    "PER_DEVICE_EVAL_BATCH_SIZE = 8\n",
    "WARMUP_STEPS = 500\n",
    "WEIGHT_DECAY = 0.01\n",
    "LOGGING_STEPS = 10\n",
    "LEARNING_RATE_SCHEDULER_TYPE = \"cosine\" # \"linear\", \"cosine\"\n",
    "\n",
    "# EXCEL\n",
    "EXCEL_PATH = 'DL2'\n",
    "\n",
    "models = [MODEL_NAME]\n",
    "for model in models:\n",
    "    start_time = time.time()\n",
    "    timestamp = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "    # Load data\n",
    "    df = load_data(dataset_name=DATA, embedding_name=EMBEDDING_NAME)\n",
    "\n",
    "    # Filter by lang\n",
    "    df = filter_by_lang(df)\n",
    "\n",
    "    # Add special tokens\n",
    "    df = add_special_tokens(df, NEW_TOKENS)\n",
    "\n",
    "    # Preprocess data\n",
    "    df = preprocess_function(df, context=CONTEXT, tweet_original=TWEET_ORIGINAL)\n",
    "\n",
    "    # Labels\n",
    "    df, labels_names, num_labels = filter_by_type(df, LABEL_COLUMN)\n",
    "    print(f\"{num_labels=}\")\n",
    "\n",
    "    for type_d in TYPES_DATASET:\n",
    "        print(\"-\"*10)\n",
    "        print(f\"{type_d=}\")\n",
    "        print(\"-\"*10)\n",
    "\n",
    "        # Prepare input (this step assumes you have a function for tokenizing or other preprocessing)\n",
    "        inputs_dataset = prepare_inputs_openai(df, label_column=LABEL_COLUMN)\n",
    "\n",
    "        # Create datasets\n",
    "        dataset = Dataset.from_dict(inputs_dataset)\n",
    "        dataset = dataset.class_encode_column(\"labels\")\n",
    "\n",
    "        # Split dataset into train, validation, and test sets\n",
    "        train_val_split = dataset.train_test_split(test_size=0.3, stratify_by_column='labels')\n",
    "        val_test_split = train_val_split['test'].train_test_split(test_size=0.5, stratify_by_column='labels')\n",
    "        \n",
    "        train_dataset = train_val_split['train']\n",
    "        val_dataset = val_test_split['train']\n",
    "        test_dataset = val_test_split['test']\n",
    "\n",
    "        # Create DatasetDict\n",
    "        datasets = DatasetDict({\n",
    "            'train': train_dataset,\n",
    "            'validation': val_dataset,\n",
    "            'test': test_dataset\n",
    "        })\n",
    "\n",
    "        # Información adicional para registrar\n",
    "        run_id = str(uuid.uuid4())\n",
    "        additional_info = {\n",
    "            'Model_Description': MODEL_NAME,\n",
    "            'Data_File': DATA,\n",
    "            'Type': type_d,\n",
    "            'Class_Counts': {\n",
    "                'train': train_dataset.features['labels'].names,\n",
    "                'validation': val_dataset.features['labels'].names,\n",
    "                'test': test_dataset.features['labels'].names,\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Load model\n",
    "        model = load_model(name=MODEL_NAME, num_labels=num_labels)\n",
    "\n",
    "        # Define training arguments\n",
    "        training_args = load_training_args(\n",
    "            context_type=type_d,\n",
    "            num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "            per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH_SIZE,\n",
    "            per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH_SIZE,\n",
    "            warmup_steps=WARMUP_STEPS,\n",
    "            weight_decay=WEIGHT_DECAY,\n",
    "            logging_steps=LOGGING_STEPS\n",
    "        )\n",
    "\n",
    "        save_results_callback = SaveResultsCallback(f\"{EXCEL_PATH}_Training_{LABEL_COLUMN}.xlsx\", training_args, run_id, additional_info, type_d, num_labels)\n",
    "\n",
    "        # Define Trainer\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=datasets['train'],\n",
    "            eval_dataset=datasets['validation'],\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks=[save_results_callback]\n",
    "        )\n",
    "\n",
    "        # Train\n",
    "        trainer.train()\n",
    "\n",
    "        # Evaluate\n",
    "        eval_results = trainer.evaluate(eval_dataset=datasets['test'])\n",
    "        results_df = pd.DataFrame([eval_results])\n",
    "\n",
    "        # Log data\n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        additional_info['Total Time'] = exec_time\n",
    "        log_data(f\"{EXCEL_PATH}_{LABEL_COLUMN}.xlsx\", run_id, eval_results, training_args, additional_info, type_d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probar Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cargar el Modelo y el Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Ruta al checkpoint\n",
    "checkpoint_path = \"./results/checkpoint-1000\"\n",
    "\n",
    "# Cargar el tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
    "\n",
    "# Cargar el modelo\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preparar el Texto para la Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prediction_input(text, tokenizer):\n",
    "    # Preprocesa el texto como lo hiciste antes de entrenar (por ejemplo, limpieza básica, truncar, etc.)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=MAX_LENGTH, truncation=TRUNCATION, padding=PADDING)\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Realizar la Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, tokenizer, model):\n",
    "    # Preparar el texto para el modelo\n",
    "    model_inputs = prepare_prediction_input(text, tokenizer)\n",
    "    \n",
    "    # Mover el modelo a CPU o GPU según esté configurado\n",
    "    model.eval()  # Poner el modelo en modo de evaluación\n",
    "    with torch.no_grad():  # No calcular gradientes\n",
    "        outputs = model(**model_inputs)\n",
    "    \n",
    "    # Obtener logits\n",
    "    logits = outputs.logits\n",
    "    \n",
    "    # Convertir los logits a probabilidades (opcional)\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    \n",
    "    # Obtener la clase predicha\n",
    "    predicted_class_index = probabilities.argmax().item()\n",
    "    \n",
    "    return predicted_class_index, probabilities.numpy()\n",
    "\n",
    "# Ejemplo de uso\n",
    "tweet = \"@Jennihermoso, ánimo campeona\"\n",
    "text = tweet_original + \" [SEP] \" + tweet + \" [SEP] \" + contexto\n",
    "print(text)\n",
    "predicted_class, probabilities = predict(text, tokenizer, model)\n",
    "print(f\"Clase predicha: {predicted_class}\")\n",
    "print(f\"Probabilidades: {probabilities}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
