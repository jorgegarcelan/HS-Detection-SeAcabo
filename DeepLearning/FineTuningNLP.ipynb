{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importaci√≥n de librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.2 (tags/v3.11.2:878ead1, Feb  7 2023, 16:38:35) [MSC v.1934 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Importaci√≥n de librer√≠as\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer, DistilBertTokenizer, BertModel, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup, RobertaTokenizer, RobertaModel\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import random\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import SnowballStemmer\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import dump\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from pysentimiento.preprocessing import preprocess_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lectura y filtrado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(df):\n",
    "    # Contar el n√∫mero de instancias por clase\n",
    "    class_counts = df['label'].value_counts()\n",
    "    # Encontrar el n√∫mero de instancias de la clase menos representada\n",
    "    min_class_count = class_counts.min()\n",
    "\n",
    "    # Crear un nuevo DataFrame vac√≠o\n",
    "    df_balanced = pd.DataFrame()\n",
    "\n",
    "    # Iterar sobre cada clase y reducir al n√∫mero de instancias de la clase menos representada\n",
    "    for label in df['label'].unique():\n",
    "        df_class = df[df['label'] == label]\n",
    "        df_class_downsampled = df_class.sample(min_class_count)\n",
    "        df_balanced = pd.concat([df_balanced, df_class_downsampled], axis=0)\n",
    "\n",
    "    # Mezclar las filas para evitar cualquier sesgo\n",
    "    df_balanced = df_balanced.sample(frac=1).reset_index(drop=True)\n",
    "    return df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Soporte de etiquetas con nombres originales:\n",
      "Comentario Positivo: 2117\n",
      "Comentario Neutro: 120\n",
      "Comentario Negativo: 435\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Autora</th>\n",
       "      <th>full_text</th>\n",
       "      <th>An√°lisis General</th>\n",
       "      <th>Contenido Negativo</th>\n",
       "      <th>Insultos</th>\n",
       "      <th>Insulto 1</th>\n",
       "      <th>Insulto 2</th>\n",
       "      <th>Insulto 3</th>\n",
       "      <th>Emisor</th>\n",
       "      <th>Contenido AV.</th>\n",
       "      <th>...</th>\n",
       "      <th>profile_url</th>\n",
       "      <th>avatar_url</th>\n",
       "      <th>verified</th>\n",
       "      <th>is_blue_verified</th>\n",
       "      <th>view_count_scaled</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>num_adjectives</th>\n",
       "      <th>label</th>\n",
       "      <th>full_text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jenni Hermoso</td>\n",
       "      <td>@Jennihermoso TODA ESPA√ëA EST√Å CONTIGO https:/...</td>\n",
       "      <td>Comentario Positivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.twitter.com/Araujismoo</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/167886449...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>14.236127</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>toda espa√±a contigo httpstcocgw7wwfpzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jenni Hermoso</td>\n",
       "      <td>@Jennihermoso Espero que te llegue todo el arr...</td>\n",
       "      <td>Comentario Positivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.twitter.com/ionebelarra</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/160626561...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12.886237</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>espero llegue arrope queremos transmitirte adm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jenni Hermoso</td>\n",
       "      <td>@Jennihermoso No est√°s solaüíú</td>\n",
       "      <td>Comentario Positivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.twitter.com/carlagaleote</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/161793790...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12.438174</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no solaüíú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jenni Hermoso</td>\n",
       "      <td>@Araujismoo @Jennihermoso She‚Äôs a legend .</td>\n",
       "      <td>Comentario Positivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.twitter.com/emmaltrix</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/169070741...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.259182</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>she ‚Äô s legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jenni Hermoso</td>\n",
       "      <td>@Jennihermoso Dilo, reina https://t.co/GasZHE70bE</td>\n",
       "      <td>Comentario Positivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.twitter.com/TirodeGraciah</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/163890386...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.113684</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dilo reina httpstcogaszhe70be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>Eva Navarro</td>\n",
       "      <td>@evaaanavarro @Paulaa_311 @Jennihermoso üíúüí™üèΩ</td>\n",
       "      <td>Comentario Positivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.twitter.com/sandrus260</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/166507079...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.254662</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>üíúüí™üèΩ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>Eva Navarro</td>\n",
       "      <td>@evaaanavarro @Jennihermoso Z https://t.co/9vH...</td>\n",
       "      <td>Comentario Positivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.twitter.com/Giorgio7716</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/164212369...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.265724</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>z httpstco9vh1vggz1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>Eva Navarro</td>\n",
       "      <td>@evaaanavarro @Jennihermoso Doblemente campeon...</td>\n",
       "      <td>Comentario Positivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.twitter.com/framarub</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/125216679...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.273240</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>doblemente campeona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>Eva Navarro</td>\n",
       "      <td>@evaaanavarro @Jennihermoso Brava!! Siempre co...</td>\n",
       "      <td>Comentario Positivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.twitter.com/Joannacolomer</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/140020219...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.279278</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>brava siempre campeonas üèÜüèÖüíú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>Eva Navarro</td>\n",
       "      <td>@evaaanavarro @Jennihermoso Y despu√©s de ver e...</td>\n",
       "      <td>Comentario Negativo</td>\n",
       "      <td>Desprestigiar V√≠ctima</td>\n",
       "      <td>Deseo de Da√±ar</td>\n",
       "      <td>Pat√©ticas</td>\n",
       "      <td>Mentirosa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fake</td>\n",
       "      <td>Si</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.twitter.com/ElJovenRicoOf</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/147480715...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.279024</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>despu√©s ver ¬øte reafirmas mentira pat√©ticas ht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2640 rows √ó 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Autora                                          full_text  \\\n",
       "0     Jenni Hermoso  @Jennihermoso TODA ESPA√ëA EST√Å CONTIGO https:/...   \n",
       "1     Jenni Hermoso  @Jennihermoso Espero que te llegue todo el arr...   \n",
       "2     Jenni Hermoso                       @Jennihermoso No est√°s solaüíú   \n",
       "3     Jenni Hermoso         @Araujismoo @Jennihermoso She‚Äôs a legend .   \n",
       "4     Jenni Hermoso  @Jennihermoso Dilo, reina https://t.co/GasZHE70bE   \n",
       "...             ...                                                ...   \n",
       "2667    Eva Navarro        @evaaanavarro @Paulaa_311 @Jennihermoso üíúüí™üèΩ   \n",
       "2668    Eva Navarro  @evaaanavarro @Jennihermoso Z https://t.co/9vH...   \n",
       "2669    Eva Navarro  @evaaanavarro @Jennihermoso Doblemente campeon...   \n",
       "2670    Eva Navarro  @evaaanavarro @Jennihermoso Brava!! Siempre co...   \n",
       "2671    Eva Navarro  @evaaanavarro @Jennihermoso Y despu√©s de ver e...   \n",
       "\n",
       "         An√°lisis General     Contenido Negativo        Insultos  Insulto 1  \\\n",
       "0     Comentario Positivo                    NaN             NaN        NaN   \n",
       "1     Comentario Positivo                    NaN             NaN        NaN   \n",
       "2     Comentario Positivo                    NaN             NaN        NaN   \n",
       "3     Comentario Positivo                    NaN             NaN        NaN   \n",
       "4     Comentario Positivo                    NaN             NaN        NaN   \n",
       "...                   ...                    ...             ...        ...   \n",
       "2667  Comentario Positivo                    NaN             NaN        NaN   \n",
       "2668  Comentario Positivo                    NaN             NaN        NaN   \n",
       "2669  Comentario Positivo                    NaN             NaN        NaN   \n",
       "2670  Comentario Positivo                    NaN             NaN        NaN   \n",
       "2671  Comentario Negativo  Desprestigiar V√≠ctima  Deseo de Da√±ar  Pat√©ticas   \n",
       "\n",
       "      Insulto 2 Insulto 3 Emisor Contenido AV.  ...  \\\n",
       "0           NaN       NaN    NaN           NaN  ...   \n",
       "1           NaN       NaN    NaN           NaN  ...   \n",
       "2           NaN       NaN    NaN           NaN  ...   \n",
       "3           NaN       NaN    NaN           NaN  ...   \n",
       "4           NaN       NaN    NaN           NaN  ...   \n",
       "...         ...       ...    ...           ...  ...   \n",
       "2667        NaN       NaN    NaN           NaN  ...   \n",
       "2668        NaN       NaN    NaN           NaN  ...   \n",
       "2669        NaN       NaN    NaN           NaN  ...   \n",
       "2670        NaN       NaN    NaN           NaN  ...   \n",
       "2671  Mentirosa       NaN   Fake            Si  ...   \n",
       "\n",
       "                                profile_url  \\\n",
       "0        https://www.twitter.com/Araujismoo   \n",
       "1       https://www.twitter.com/ionebelarra   \n",
       "2      https://www.twitter.com/carlagaleote   \n",
       "3         https://www.twitter.com/emmaltrix   \n",
       "4     https://www.twitter.com/TirodeGraciah   \n",
       "...                                     ...   \n",
       "2667     https://www.twitter.com/sandrus260   \n",
       "2668    https://www.twitter.com/Giorgio7716   \n",
       "2669       https://www.twitter.com/framarub   \n",
       "2670  https://www.twitter.com/Joannacolomer   \n",
       "2671  https://www.twitter.com/ElJovenRicoOf   \n",
       "\n",
       "                                             avatar_url  verified  \\\n",
       "0     https://pbs.twimg.com/profile_images/167886449...     False   \n",
       "1     https://pbs.twimg.com/profile_images/160626561...     False   \n",
       "2     https://pbs.twimg.com/profile_images/161793790...     False   \n",
       "3     https://pbs.twimg.com/profile_images/169070741...     False   \n",
       "4     https://pbs.twimg.com/profile_images/163890386...     False   \n",
       "...                                                 ...       ...   \n",
       "2667  https://pbs.twimg.com/profile_images/166507079...     False   \n",
       "2668  https://pbs.twimg.com/profile_images/164212369...     False   \n",
       "2669  https://pbs.twimg.com/profile_images/125216679...     False   \n",
       "2670  https://pbs.twimg.com/profile_images/140020219...     False   \n",
       "2671  https://pbs.twimg.com/profile_images/147480715...     False   \n",
       "\n",
       "      is_blue_verified  view_count_scaled  mention_count  tweet_length  \\\n",
       "0                 True          14.236127              1            62   \n",
       "1                False          12.886237              1           113   \n",
       "2                False          12.438174              1            28   \n",
       "3                 True           7.259182              2            42   \n",
       "4                 True           7.113684              1            49   \n",
       "...                ...                ...            ...           ...   \n",
       "2667             False          -0.254662              3            43   \n",
       "2668             False          -0.265724              2            53   \n",
       "2669             False          -0.273240              2            73   \n",
       "2670             False          -0.279278              2            72   \n",
       "2671             False          -0.279024              2           131   \n",
       "\n",
       "      num_adjectives label                                full_text_processed  \n",
       "0                  1     0             toda espa√±a contigo httpstcocgw7wwfpzi  \n",
       "1                  3     0  espero llegue arrope queremos transmitirte adm...  \n",
       "2                  1     0                                           no solaüíú  \n",
       "3                  1     0                                     she ‚Äô s legend  \n",
       "4                  1     0                      dilo reina httpstcogaszhe70be  \n",
       "...              ...   ...                                                ...  \n",
       "2667               1     0                                                üíúüí™üèΩ  \n",
       "2668               1     0                               z httpstco9vh1vggz1h  \n",
       "2669               1     0                                doblemente campeona  \n",
       "2670               1     0                        brava siempre campeonas üèÜüèÖüíú  \n",
       "2671               1     2  despu√©s ver ¬øte reafirmas mentira pat√©ticas ht...  \n",
       "\n",
       "[2640 rows x 52 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data():\n",
    "    # Leer el archivo y realizar transformaciones en los datos\n",
    "    df = pd.read_csv(\"data/BBDD_SeAcabo.csv\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def process_data(df, type_id):\n",
    "\n",
    "    # Normalize \"view_count\"\n",
    "    scaler = StandardScaler()\n",
    "    df['view_count_scaled'] = scaler.fit_transform(df[['view_count']])\n",
    "\n",
    "    # User Mentions\n",
    "    def count_user_mentions(mentions):\n",
    "        if pd.isna(mentions) or mentions == \"\":\n",
    "            return 0\n",
    "        else:\n",
    "            return len(mentions.split(';'))\n",
    "        \n",
    "    df['mention_count'] = df['user_mentions'].apply(count_user_mentions)\n",
    "\n",
    "    # Length Tweet\n",
    "    df['tweet_length'] = df['full_text'].str.len()\n",
    "\n",
    "    # Num Adjetives\n",
    "    def count_adjectives(text):\n",
    "        words = word_tokenize(text)\n",
    "        pos_tags = pos_tag(words)\n",
    "        return sum(1 for word, tag in pos_tags if tag.startswith('JJ'))\n",
    "    df['num_adjectives'] = df['full_text'].apply(count_adjectives)\n",
    "\n",
    "    #[\"analisis_general\", \"contenido_negativo\", \"insultos\"]\n",
    "    if type_id == \"analisis_general\":\n",
    "        # Define the specific labels to keep\n",
    "        etiquetas = [\"Comentario Positivo\", \"Comentario Negativo\", \"Comentario Neutro\"]\n",
    "\n",
    "\n",
    "        # Remove NAs\n",
    "        df = df.dropna(subset=['An√°lisis General'])\n",
    "        \n",
    "\n",
    "        # Factorize the 'An√°lisis General' column\n",
    "        labels, labels_names = pd.factorize(df['An√°lisis General'])\n",
    "\n",
    "        # 'labels' now contains the numeric representation of your original labels\n",
    "        # 'label_names' contains the unique values from your original column in the order they were encoded\n",
    "\n",
    "        # Replace the original column with the numeric labels\n",
    "        df['label'] = labels\n",
    "\n",
    "        # If you want to keep a record of the mapping from the original labels to the numeric labels\n",
    "        label_mapping = dict(zip(labels_names, range(len(labels_names))))\n",
    "        #print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "        n_labels = 3\n",
    "        label_dict = {'Comentario Positivo': 0, 'Comentario Negativo': 1, 'Comentario Neutro': 2}\n",
    "\n",
    "    if type_id == \"contenido_negativo\":\n",
    "\n",
    "        # Filtrar el DataFrame para seleccionar solo los \"Comentario Negativo\"\n",
    "        df = df.loc[df['An√°lisis General'] == 'Comentario Negativo']\n",
    "\n",
    "        # Define the specific labels to keep\n",
    "        etiquetas = [\"Desprestigiar V√≠ctima\", \"Desprestigiar Acto\", \"Insultos\", \"Desprestigiar Deportista Autora\", \"Sexualizaci√≥n / Objetivizaci√≥n\", \"Estereotipos de G√©nero\"]\n",
    "        df['Contenido Negativo'] = df['Contenido Negativo'].where(df['Contenido Negativo'].isin(etiquetas))\n",
    "\n",
    "        # Remove NAs\n",
    "        df = df.dropna(subset=['Contenido Negativo'])\n",
    "        \n",
    "\n",
    "        # Factorize the 'An√°lisis General' column\n",
    "        labels, labels_names = pd.factorize(df['Contenido Negativo'])\n",
    "\n",
    "        # 'labels' now contains the numeric representation of your original labels\n",
    "        # 'label_names' contains the unique values from your original column in the order they were encoded\n",
    "\n",
    "        # Replace the original column with the numeric labels\n",
    "        df['label'] = labels\n",
    "\n",
    "        # If you want to keep a record of the mapping from the original labels to the numeric labels\n",
    "        label_mapping = dict(zip(labels_names, range(len(labels_names))))\n",
    "        #print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "        n_labels = 6\n",
    "        label_dict = {'Desprestigiar Acto': 0, 'Desprestigiar Deportista Autora': 1, 'Desprestigiar V√≠ctima': 2, 'Insultos': 3}\n",
    "\n",
    "\n",
    "    if type_id == \"insultos\":\n",
    "\n",
    "        # Filtrar el DataFrame para seleccionar solo los \"Comentario Negativo\"\n",
    "        df = df.loc[df['An√°lisis General'] == 'Comentario Negativo']\n",
    "\n",
    "        # Define the specific labels to keep\n",
    "        etiquetas = [\"Deseo de Da√±ar\", \"Gen√©ricos\", \"Sexistas/mis√≥ginos\", \"\"]\n",
    "\n",
    "        # Replace labels that are not in the list with \"Gen√©ricos\"\n",
    "        df['Insultos'] = df['Insultos'].where(df['Insultos'].isin(etiquetas), other=\"Gen√©ricos\")\n",
    "\n",
    "        # Remove NAs\n",
    "        df = df.dropna(subset=['Insultos'])\n",
    "        \n",
    "\n",
    "        # Factorize the 'Insultos' column\n",
    "        labels, labels_names = pd.factorize(df['Insultos'])\n",
    "\n",
    "        # 'labels' now contains the numeric representation of your original labels\n",
    "        # 'label_names' contains the unique values from your original column in the order they were encoded\n",
    "\n",
    "        # Replace the original column with the numeric labels\n",
    "        df['label'] = labels\n",
    "\n",
    "        # If you want to keep a record of the mapping from the original labels to the numeric labels\n",
    "        label_mapping = dict(zip(labels_names, range(len(labels_names))))\n",
    "        #print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "        n_labels = 3\n",
    "        label_dict = {'Gen√©ricos': 0, 'Sexistas/mis√≥ginos': 1, 'Deseo de Da√±ar': 2}\n",
    "\n",
    "\n",
    "    # Contar el soporte de cada etiqueta\n",
    "    soporte_etiquetas = df['label'].value_counts()\n",
    "\n",
    "    # Imprimir el soporte para cada etiqueta\n",
    "    print(\"\\nSoporte de etiquetas con nombres originales:\")\n",
    "    for nombre_etiqueta, codigo in label_mapping.items():\n",
    "        print(f\"{nombre_etiqueta}: {soporte_etiquetas[codigo]}\")\n",
    "    \n",
    "    # Initialize stemmer\n",
    "    ##stemmer = SnowballStemmer('spanish')\n",
    "    \n",
    "    # Define function to remove stopwords, punctuation, and apply stemming\n",
    "    def remove_spanish_stopwords(text):\n",
    "\n",
    "        # Eliminar menciones a usuarios (palabras que comienzan con @)\n",
    "        text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "        # Eliminar enlaces (todo lo que comienza con http o https)\n",
    "        #text = re.sub(r'http\\S+|https\\S+', '', text)\n",
    "\n",
    "        # Remove punctuation\n",
    "        text = ''.join([char for char in text if char not in string.punctuation])\n",
    "        \n",
    "        # Remove stopwords\n",
    "        spanish_stopwords = set(stopwords.words('spanish'))\n",
    "        spanish_stopwords.remove(\"no\")  # Retain \"no\" as it provides negative context\n",
    "        words = word_tokenize(text)\n",
    "        filtered_words = [word.lower() for word in words if word.lower() not in spanish_stopwords]\n",
    "        \n",
    "        # Apply stemming (MIRAR)\n",
    "        ##stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "        \n",
    "        ##return ' '.join(stemmed_words)  \n",
    "        return ' '.join(filtered_words)\n",
    "\n",
    "    df['full_text_processed'] = df['full_text'].apply(remove_spanish_stopwords)\n",
    "    # Eliminar filas donde 'full_text_processed' es una cadena vac√≠a\n",
    "    df = df[df['full_text_processed'] != \"\"]\n",
    "\n",
    "\n",
    "    return df, labels_names, n_labels, label_dict\n",
    "\n",
    "type_id = \"analisis_general\" #[\"analisis_general\", \"contenido_negativo\", \"insultos\"]\n",
    "df = load_data()\n",
    "df, labels_names, n_labels, label_dict = process_data(df, type_id)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Definici√≥n del modelo y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizaci√≥n y codificaci√≥n de los datos\n",
    "from transformers import RobertaModel, RobertaTokenizer, AutoTokenizer, XLMRobertaModel\n",
    "\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "#model = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "#model = BertModel.from_pretrained(\"bert-large-cased\")\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased') #beto\n",
    "#model = BertModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\") #beto\n",
    "\n",
    "#tokenizer = RobertaTokenizer.from_pretrained('PlanTL-GOB-ES/roberta-base-bne') \n",
    "#model = RobertaModel.from_pretrained(\"PlanTL-GOB-ES/roberta-base-bne\") \n",
    "\n",
    "#tokenizer = RobertaTokenizer.from_pretrained('PlanTL-GOB-ES/roberta-large-bne') \n",
    "#model = RobertaModel.from_pretrained(\"PlanTL-GOB-ES/roberta-large-bne\") \n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
    "#model = XLMRobertaModel.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorge\\AppData\\Local\\Temp\\ipykernel_41272\\3795349859.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'train' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[X_train.index, 'data_type'] = 'train'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "embeddings.word_embeddings.weight\n",
      "embeddings.position_embeddings.weight\n",
      "embeddings.token_type_embeddings.weight\n",
      "embeddings.LayerNorm.weight\n",
      "embeddings.LayerNorm.bias\n",
      "encoder.layer.0.attention.self.query.weight\n",
      "encoder.layer.0.attention.self.query.bias\n",
      "encoder.layer.0.attention.self.key.weight\n",
      "encoder.layer.0.attention.self.key.bias\n",
      "encoder.layer.0.attention.self.value.weight\n",
      "encoder.layer.0.attention.self.value.bias\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "encoder.layer.0.attention.output.LayerNorm.weight\n",
      "encoder.layer.0.attention.output.LayerNorm.bias\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "encoder.layer.0.output.dense.weight\n",
      "encoder.layer.0.output.dense.bias\n",
      "encoder.layer.0.output.LayerNorm.weight\n",
      "encoder.layer.0.output.LayerNorm.bias\n",
      "encoder.layer.1.attention.self.query.weight\n",
      "encoder.layer.1.attention.self.query.bias\n",
      "encoder.layer.1.attention.self.key.weight\n",
      "encoder.layer.1.attention.self.key.bias\n",
      "encoder.layer.1.attention.self.value.weight\n",
      "encoder.layer.1.attention.self.value.bias\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "encoder.layer.1.attention.output.LayerNorm.weight\n",
      "encoder.layer.1.attention.output.LayerNorm.bias\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "encoder.layer.1.output.dense.weight\n",
      "encoder.layer.1.output.dense.bias\n",
      "encoder.layer.1.output.LayerNorm.weight\n",
      "encoder.layer.1.output.LayerNorm.bias\n",
      "encoder.layer.2.attention.self.query.weight\n",
      "encoder.layer.2.attention.self.query.bias\n",
      "encoder.layer.2.attention.self.key.weight\n",
      "encoder.layer.2.attention.self.key.bias\n",
      "encoder.layer.2.attention.self.value.weight\n",
      "encoder.layer.2.attention.self.value.bias\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "encoder.layer.2.attention.output.LayerNorm.weight\n",
      "encoder.layer.2.attention.output.LayerNorm.bias\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "encoder.layer.2.output.dense.weight\n",
      "encoder.layer.2.output.dense.bias\n",
      "encoder.layer.2.output.LayerNorm.weight\n",
      "encoder.layer.2.output.LayerNorm.bias\n",
      "encoder.layer.3.attention.self.query.weight\n",
      "encoder.layer.3.attention.self.query.bias\n",
      "encoder.layer.3.attention.self.key.weight\n",
      "encoder.layer.3.attention.self.key.bias\n",
      "encoder.layer.3.attention.self.value.weight\n",
      "encoder.layer.3.attention.self.value.bias\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "encoder.layer.3.attention.output.LayerNorm.weight\n",
      "encoder.layer.3.attention.output.LayerNorm.bias\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "encoder.layer.3.output.dense.weight\n",
      "encoder.layer.3.output.dense.bias\n",
      "encoder.layer.3.output.LayerNorm.weight\n",
      "encoder.layer.3.output.LayerNorm.bias\n",
      "encoder.layer.4.attention.self.query.weight\n",
      "encoder.layer.4.attention.self.query.bias\n",
      "encoder.layer.4.attention.self.key.weight\n",
      "encoder.layer.4.attention.self.key.bias\n",
      "encoder.layer.4.attention.self.value.weight\n",
      "encoder.layer.4.attention.self.value.bias\n",
      "encoder.layer.4.attention.output.dense.weight\n",
      "encoder.layer.4.attention.output.dense.bias\n",
      "encoder.layer.4.attention.output.LayerNorm.weight\n",
      "encoder.layer.4.attention.output.LayerNorm.bias\n",
      "encoder.layer.4.intermediate.dense.weight\n",
      "encoder.layer.4.intermediate.dense.bias\n",
      "encoder.layer.4.output.dense.weight\n",
      "encoder.layer.4.output.dense.bias\n",
      "encoder.layer.4.output.LayerNorm.weight\n",
      "encoder.layer.4.output.LayerNorm.bias\n",
      "encoder.layer.5.attention.self.query.weight\n",
      "encoder.layer.5.attention.self.query.bias\n",
      "encoder.layer.5.attention.self.key.weight\n",
      "encoder.layer.5.attention.self.key.bias\n",
      "encoder.layer.5.attention.self.value.weight\n",
      "encoder.layer.5.attention.self.value.bias\n",
      "encoder.layer.5.attention.output.dense.weight\n",
      "encoder.layer.5.attention.output.dense.bias\n",
      "encoder.layer.5.attention.output.LayerNorm.weight\n",
      "encoder.layer.5.attention.output.LayerNorm.bias\n",
      "encoder.layer.5.intermediate.dense.weight\n",
      "encoder.layer.5.intermediate.dense.bias\n",
      "encoder.layer.5.output.dense.weight\n",
      "encoder.layer.5.output.dense.bias\n",
      "encoder.layer.5.output.LayerNorm.weight\n",
      "encoder.layer.5.output.LayerNorm.bias\n",
      "encoder.layer.6.attention.self.query.weight\n",
      "encoder.layer.6.attention.self.query.bias\n",
      "encoder.layer.6.attention.self.key.weight\n",
      "encoder.layer.6.attention.self.key.bias\n",
      "encoder.layer.6.attention.self.value.weight\n",
      "encoder.layer.6.attention.self.value.bias\n",
      "encoder.layer.6.attention.output.dense.weight\n",
      "encoder.layer.6.attention.output.dense.bias\n",
      "encoder.layer.6.attention.output.LayerNorm.weight\n",
      "encoder.layer.6.attention.output.LayerNorm.bias\n",
      "encoder.layer.6.intermediate.dense.weight\n",
      "encoder.layer.6.intermediate.dense.bias\n",
      "encoder.layer.6.output.dense.weight\n",
      "encoder.layer.6.output.dense.bias\n",
      "encoder.layer.6.output.LayerNorm.weight\n",
      "encoder.layer.6.output.LayerNorm.bias\n",
      "encoder.layer.7.attention.self.query.weight\n",
      "encoder.layer.7.attention.self.query.bias\n",
      "encoder.layer.7.attention.self.key.weight\n",
      "encoder.layer.7.attention.self.key.bias\n",
      "encoder.layer.7.attention.self.value.weight\n",
      "encoder.layer.7.attention.self.value.bias\n",
      "encoder.layer.7.attention.output.dense.weight\n",
      "encoder.layer.7.attention.output.dense.bias\n",
      "encoder.layer.7.attention.output.LayerNorm.weight\n",
      "encoder.layer.7.attention.output.LayerNorm.bias\n",
      "encoder.layer.7.intermediate.dense.weight\n",
      "encoder.layer.7.intermediate.dense.bias\n",
      "encoder.layer.7.output.dense.weight\n",
      "encoder.layer.7.output.dense.bias\n",
      "encoder.layer.7.output.LayerNorm.weight\n",
      "encoder.layer.7.output.LayerNorm.bias\n",
      "encoder.layer.8.attention.self.query.weight\n",
      "encoder.layer.8.attention.self.query.bias\n",
      "encoder.layer.8.attention.self.key.weight\n",
      "encoder.layer.8.attention.self.key.bias\n",
      "encoder.layer.8.attention.self.value.weight\n",
      "encoder.layer.8.attention.self.value.bias\n",
      "encoder.layer.8.attention.output.dense.weight\n",
      "encoder.layer.8.attention.output.dense.bias\n",
      "encoder.layer.8.attention.output.LayerNorm.weight\n",
      "encoder.layer.8.attention.output.LayerNorm.bias\n",
      "encoder.layer.8.intermediate.dense.weight\n",
      "encoder.layer.8.intermediate.dense.bias\n",
      "encoder.layer.8.output.dense.weight\n",
      "encoder.layer.8.output.dense.bias\n",
      "encoder.layer.8.output.LayerNorm.weight\n",
      "encoder.layer.8.output.LayerNorm.bias\n",
      "encoder.layer.9.attention.self.query.weight\n",
      "encoder.layer.9.attention.self.query.bias\n",
      "encoder.layer.9.attention.self.key.weight\n",
      "encoder.layer.9.attention.self.key.bias\n",
      "encoder.layer.9.attention.self.value.weight\n",
      "encoder.layer.9.attention.self.value.bias\n",
      "encoder.layer.9.attention.output.dense.weight\n",
      "encoder.layer.9.attention.output.dense.bias\n",
      "encoder.layer.9.attention.output.LayerNorm.weight\n",
      "encoder.layer.9.attention.output.LayerNorm.bias\n",
      "encoder.layer.9.intermediate.dense.weight\n",
      "encoder.layer.9.intermediate.dense.bias\n",
      "encoder.layer.9.output.dense.weight\n",
      "encoder.layer.9.output.dense.bias\n",
      "encoder.layer.9.output.LayerNorm.weight\n",
      "encoder.layer.9.output.LayerNorm.bias\n",
      "encoder.layer.10.attention.self.query.weight\n",
      "encoder.layer.10.attention.self.query.bias\n",
      "encoder.layer.10.attention.self.key.weight\n",
      "encoder.layer.10.attention.self.key.bias\n",
      "encoder.layer.10.attention.self.value.weight\n",
      "encoder.layer.10.attention.self.value.bias\n",
      "encoder.layer.10.attention.output.dense.weight\n",
      "encoder.layer.10.attention.output.dense.bias\n",
      "encoder.layer.10.attention.output.LayerNorm.weight\n",
      "encoder.layer.10.attention.output.LayerNorm.bias\n",
      "encoder.layer.10.intermediate.dense.weight\n",
      "encoder.layer.10.intermediate.dense.bias\n",
      "encoder.layer.10.output.dense.weight\n",
      "encoder.layer.10.output.dense.bias\n",
      "encoder.layer.10.output.LayerNorm.weight\n",
      "encoder.layer.10.output.LayerNorm.bias\n",
      "encoder.layer.11.attention.self.query.weight\n",
      "encoder.layer.11.attention.self.query.bias\n",
      "encoder.layer.11.attention.self.key.weight\n",
      "encoder.layer.11.attention.self.key.bias\n",
      "encoder.layer.11.attention.self.value.weight\n",
      "encoder.layer.11.attention.self.value.bias\n",
      "encoder.layer.11.attention.output.dense.weight\n",
      "encoder.layer.11.attention.output.dense.bias\n",
      "encoder.layer.11.attention.output.LayerNorm.weight\n",
      "encoder.layer.11.attention.output.LayerNorm.bias\n",
      "encoder.layer.11.intermediate.dense.weight\n",
      "encoder.layer.11.intermediate.dense.bias\n",
      "encoder.layer.11.output.dense.weight\n",
      "encoder.layer.11.output.dense.bias\n",
      "encoder.layer.11.output.LayerNorm.weight\n",
      "encoder.layer.11.output.LayerNorm.bias\n",
      "pooler.dense.weight\n",
      "pooler.dense.bias\n",
      "I will be frozen: embeddings.word_embeddings.weight\n",
      "I will be frozen: embeddings.position_embeddings.weight\n",
      "I will be frozen: embeddings.token_type_embeddings.weight\n",
      "I will be frozen: embeddings.LayerNorm.weight\n",
      "I will be frozen: embeddings.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.0.attention.self.query.weight\n",
      "I will be frozen: encoder.layer.0.attention.self.query.bias\n",
      "I will be frozen: encoder.layer.0.attention.self.key.weight\n",
      "I will be frozen: encoder.layer.0.attention.self.key.bias\n",
      "I will be frozen: encoder.layer.0.attention.self.value.weight\n",
      "I will be frozen: encoder.layer.0.attention.self.value.bias\n",
      "I will be frozen: encoder.layer.0.attention.output.dense.weight\n",
      "I will be frozen: encoder.layer.0.attention.output.dense.bias\n",
      "I will be frozen: encoder.layer.0.attention.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.0.attention.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.0.intermediate.dense.weight\n",
      "I will be frozen: encoder.layer.0.intermediate.dense.bias\n",
      "I will be frozen: encoder.layer.0.output.dense.weight\n",
      "I will be frozen: encoder.layer.0.output.dense.bias\n",
      "I will be frozen: encoder.layer.0.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.0.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.1.attention.self.query.weight\n",
      "I will be frozen: encoder.layer.1.attention.self.query.bias\n",
      "I will be frozen: encoder.layer.1.attention.self.key.weight\n",
      "I will be frozen: encoder.layer.1.attention.self.key.bias\n",
      "I will be frozen: encoder.layer.1.attention.self.value.weight\n",
      "I will be frozen: encoder.layer.1.attention.self.value.bias\n",
      "I will be frozen: encoder.layer.1.attention.output.dense.weight\n",
      "I will be frozen: encoder.layer.1.attention.output.dense.bias\n",
      "I will be frozen: encoder.layer.1.attention.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.1.attention.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.1.intermediate.dense.weight\n",
      "I will be frozen: encoder.layer.1.intermediate.dense.bias\n",
      "I will be frozen: encoder.layer.1.output.dense.weight\n",
      "I will be frozen: encoder.layer.1.output.dense.bias\n",
      "I will be frozen: encoder.layer.1.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.1.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.2.attention.self.query.weight\n",
      "I will be frozen: encoder.layer.2.attention.self.query.bias\n",
      "I will be frozen: encoder.layer.2.attention.self.key.weight\n",
      "I will be frozen: encoder.layer.2.attention.self.key.bias\n",
      "I will be frozen: encoder.layer.2.attention.self.value.weight\n",
      "I will be frozen: encoder.layer.2.attention.self.value.bias\n",
      "I will be frozen: encoder.layer.2.attention.output.dense.weight\n",
      "I will be frozen: encoder.layer.2.attention.output.dense.bias\n",
      "I will be frozen: encoder.layer.2.attention.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.2.attention.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.2.intermediate.dense.weight\n",
      "I will be frozen: encoder.layer.2.intermediate.dense.bias\n",
      "I will be frozen: encoder.layer.2.output.dense.weight\n",
      "I will be frozen: encoder.layer.2.output.dense.bias\n",
      "I will be frozen: encoder.layer.2.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.2.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.3.attention.self.query.weight\n",
      "I will be frozen: encoder.layer.3.attention.self.query.bias\n",
      "I will be frozen: encoder.layer.3.attention.self.key.weight\n",
      "I will be frozen: encoder.layer.3.attention.self.key.bias\n",
      "I will be frozen: encoder.layer.3.attention.self.value.weight\n",
      "I will be frozen: encoder.layer.3.attention.self.value.bias\n",
      "I will be frozen: encoder.layer.3.attention.output.dense.weight\n",
      "I will be frozen: encoder.layer.3.attention.output.dense.bias\n",
      "I will be frozen: encoder.layer.3.attention.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.3.attention.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.3.intermediate.dense.weight\n",
      "I will be frozen: encoder.layer.3.intermediate.dense.bias\n",
      "I will be frozen: encoder.layer.3.output.dense.weight\n",
      "I will be frozen: encoder.layer.3.output.dense.bias\n",
      "I will be frozen: encoder.layer.3.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.3.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.4.attention.self.query.weight\n",
      "I will be frozen: encoder.layer.4.attention.self.query.bias\n",
      "I will be frozen: encoder.layer.4.attention.self.key.weight\n",
      "I will be frozen: encoder.layer.4.attention.self.key.bias\n",
      "I will be frozen: encoder.layer.4.attention.self.value.weight\n",
      "I will be frozen: encoder.layer.4.attention.self.value.bias\n",
      "I will be frozen: encoder.layer.4.attention.output.dense.weight\n",
      "I will be frozen: encoder.layer.4.attention.output.dense.bias\n",
      "I will be frozen: encoder.layer.4.attention.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.4.attention.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.4.intermediate.dense.weight\n",
      "I will be frozen: encoder.layer.4.intermediate.dense.bias\n",
      "I will be frozen: encoder.layer.4.output.dense.weight\n",
      "I will be frozen: encoder.layer.4.output.dense.bias\n",
      "I will be frozen: encoder.layer.4.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.4.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.5.attention.self.query.weight\n",
      "I will be frozen: encoder.layer.5.attention.self.query.bias\n",
      "I will be frozen: encoder.layer.5.attention.self.key.weight\n",
      "I will be frozen: encoder.layer.5.attention.self.key.bias\n",
      "I will be frozen: encoder.layer.5.attention.self.value.weight\n",
      "I will be frozen: encoder.layer.5.attention.self.value.bias\n",
      "I will be frozen: encoder.layer.5.attention.output.dense.weight\n",
      "I will be frozen: encoder.layer.5.attention.output.dense.bias\n",
      "I will be frozen: encoder.layer.5.attention.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.5.attention.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.5.intermediate.dense.weight\n",
      "I will be frozen: encoder.layer.5.intermediate.dense.bias\n",
      "I will be frozen: encoder.layer.5.output.dense.weight\n",
      "I will be frozen: encoder.layer.5.output.dense.bias\n",
      "I will be frozen: encoder.layer.5.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.5.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.6.attention.self.query.weight\n",
      "I will be frozen: encoder.layer.6.attention.self.query.bias\n",
      "I will be frozen: encoder.layer.6.attention.self.key.weight\n",
      "I will be frozen: encoder.layer.6.attention.self.key.bias\n",
      "I will be frozen: encoder.layer.6.attention.self.value.weight\n",
      "I will be frozen: encoder.layer.6.attention.self.value.bias\n",
      "I will be frozen: encoder.layer.6.attention.output.dense.weight\n",
      "I will be frozen: encoder.layer.6.attention.output.dense.bias\n",
      "I will be frozen: encoder.layer.6.attention.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.6.attention.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.6.intermediate.dense.weight\n",
      "I will be frozen: encoder.layer.6.intermediate.dense.bias\n",
      "I will be frozen: encoder.layer.6.output.dense.weight\n",
      "I will be frozen: encoder.layer.6.output.dense.bias\n",
      "I will be frozen: encoder.layer.6.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.6.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.7.attention.self.query.weight\n",
      "I will be frozen: encoder.layer.7.attention.self.query.bias\n",
      "I will be frozen: encoder.layer.7.attention.self.key.weight\n",
      "I will be frozen: encoder.layer.7.attention.self.key.bias\n",
      "I will be frozen: encoder.layer.7.attention.self.value.weight\n",
      "I will be frozen: encoder.layer.7.attention.self.value.bias\n",
      "I will be frozen: encoder.layer.7.attention.output.dense.weight\n",
      "I will be frozen: encoder.layer.7.attention.output.dense.bias\n",
      "I will be frozen: encoder.layer.7.attention.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.7.attention.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.7.intermediate.dense.weight\n",
      "I will be frozen: encoder.layer.7.intermediate.dense.bias\n",
      "I will be frozen: encoder.layer.7.output.dense.weight\n",
      "I will be frozen: encoder.layer.7.output.dense.bias\n",
      "I will be frozen: encoder.layer.7.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.7.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.8.attention.self.query.weight\n",
      "I will be frozen: encoder.layer.8.attention.self.query.bias\n",
      "I will be frozen: encoder.layer.8.attention.self.key.weight\n",
      "I will be frozen: encoder.layer.8.attention.self.key.bias\n",
      "I will be frozen: encoder.layer.8.attention.self.value.weight\n",
      "I will be frozen: encoder.layer.8.attention.self.value.bias\n",
      "I will be frozen: encoder.layer.8.attention.output.dense.weight\n",
      "I will be frozen: encoder.layer.8.attention.output.dense.bias\n",
      "I will be frozen: encoder.layer.8.attention.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.8.attention.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.8.intermediate.dense.weight\n",
      "I will be frozen: encoder.layer.8.intermediate.dense.bias\n",
      "I will be frozen: encoder.layer.8.output.dense.weight\n",
      "I will be frozen: encoder.layer.8.output.dense.bias\n",
      "I will be frozen: encoder.layer.8.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.8.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.9.attention.self.query.weight\n",
      "I will be frozen: encoder.layer.9.attention.self.query.bias\n",
      "I will be frozen: encoder.layer.9.attention.self.key.weight\n",
      "I will be frozen: encoder.layer.9.attention.self.key.bias\n",
      "I will be frozen: encoder.layer.9.attention.self.value.weight\n",
      "I will be frozen: encoder.layer.9.attention.self.value.bias\n",
      "I will be frozen: encoder.layer.9.attention.output.dense.weight\n",
      "I will be frozen: encoder.layer.9.attention.output.dense.bias\n",
      "I will be frozen: encoder.layer.9.attention.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.9.attention.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.9.intermediate.dense.weight\n",
      "I will be frozen: encoder.layer.9.intermediate.dense.bias\n",
      "I will be frozen: encoder.layer.9.output.dense.weight\n",
      "I will be frozen: encoder.layer.9.output.dense.bias\n",
      "I will be frozen: encoder.layer.9.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.9.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.10.attention.self.query.weight\n",
      "I will be frozen: encoder.layer.10.attention.self.query.bias\n",
      "I will be frozen: encoder.layer.10.attention.self.key.weight\n",
      "I will be frozen: encoder.layer.10.attention.self.key.bias\n",
      "I will be frozen: encoder.layer.10.attention.self.value.weight\n",
      "I will be frozen: encoder.layer.10.attention.self.value.bias\n",
      "I will be frozen: encoder.layer.10.attention.output.dense.weight\n",
      "I will be frozen: encoder.layer.10.attention.output.dense.bias\n",
      "I will be frozen: encoder.layer.10.attention.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.10.attention.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.10.intermediate.dense.weight\n",
      "I will be frozen: encoder.layer.10.intermediate.dense.bias\n",
      "I will be frozen: encoder.layer.10.output.dense.weight\n",
      "I will be frozen: encoder.layer.10.output.dense.bias\n",
      "I will be frozen: encoder.layer.10.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.10.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.11.attention.self.query.weight\n",
      "I will be frozen: encoder.layer.11.attention.self.query.bias\n",
      "I will be frozen: encoder.layer.11.attention.self.key.weight\n",
      "I will be frozen: encoder.layer.11.attention.self.key.bias\n",
      "I will be frozen: encoder.layer.11.attention.self.value.weight\n",
      "I will be frozen: encoder.layer.11.attention.self.value.bias\n",
      "I will be frozen: encoder.layer.11.attention.output.dense.weight\n",
      "I will be frozen: encoder.layer.11.attention.output.dense.bias\n",
      "I will be frozen: encoder.layer.11.attention.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.11.attention.output.LayerNorm.bias\n",
      "I will be frozen: encoder.layer.11.intermediate.dense.weight\n",
      "I will be frozen: encoder.layer.11.intermediate.dense.bias\n",
      "I will be frozen: encoder.layer.11.output.dense.weight\n",
      "I will be frozen: encoder.layer.11.output.dense.bias\n",
      "I will be frozen: encoder.layer.11.output.LayerNorm.weight\n",
      "I will be frozen: encoder.layer.11.output.LayerNorm.bias\n",
      "I will be frozen: pooler.dense.weight\n",
      "I will be frozen: pooler.dense.bias\n",
      "ROBERTAClass(\n",
      "  (l1): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=264, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (classifier): Linear(in_features=264, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Hiperpar√°metros del modelo\n",
    "BATCH_SIZE = 16  # [16,32,64]\n",
    "MAX_SEQUENCE = 256 # [128, 256, 512]\n",
    "LEARNING_RATE = 2e-5 # [1e-4, 5e-5, 1e-5]\n",
    "EPOCH = 10 # [10, 15, 20]\n",
    "\n",
    "\n",
    "\n",
    "# Divisi√≥n de datos en conjuntos de entrenamiento y validaci√≥n\n",
    "X_train, X_val, y_train, y_val = train_test_split(df['full_text_processed'], \n",
    "                                                df['label'], \n",
    "                                                test_size=0.2, \n",
    "                                                random_state=42, \n",
    "                                                stratify=df['label'])\n",
    "df.loc[X_train.index, 'data_type'] = 'train'\n",
    "df.loc[X_val.index, 'data_type'] = 'val'\n",
    "df.groupby(['label', 'data_type']).count()\n",
    "\n",
    "# Prepara los datos para el entrenamiento y validaci√≥n\n",
    "encoded_data_train = tokenizer.batch_encode_plus( \n",
    "    df[df.data_type=='train']['full_text_processed'].values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding=True, \n",
    "    truncation=True,\n",
    "    max_length=MAX_SEQUENCE, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val']['full_text_processed'].values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding=True, \n",
    "    truncation=True,\n",
    "    max_length=MAX_SEQUENCE,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train']['label'].values)\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val']['label'].values)\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "len(dataset_train), len(dataset_val)\n",
    "\n",
    "\n",
    "\n",
    "# Configuraci√≥n del dispositivo (GPU o CPU) y congelaci√≥n de par√°metros del modelo base\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "\n",
    "for name, param in list(model.named_parameters()):#[:-20]:\n",
    "    print('I will be frozen: {}'.format(name))\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "# Definici√≥n de la arquitectura del modelo de clasificaci√≥n\n",
    "class ROBERTAClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ROBERTAClass, self).__init__()\n",
    "        self.l1 = model\n",
    "        self.pre_classifier = torch.nn.Linear(768, 264) # roberta large 1024, roberta base 768\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(264, n_labels)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Use the pooled output (the second element of the outputs tuple) for classification\n",
    "        # This is typically what you want for a classification task.\n",
    "        pooler_output = outputs[1]\n",
    "\n",
    "        pooler_output = self.pre_classifier(pooler_output)\n",
    "        pooler_output = torch.nn.ReLU()(pooler_output)\n",
    "        pooler_output = self.dropout(pooler_output)\n",
    "        output = self.classifier(pooler_output)\n",
    "        return output\n",
    "\n",
    "# Instanciaci√≥n y configuraci√≥n del modelo\n",
    "model = ROBERTAClass()\n",
    "model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Configuraci√≥n de los dataloaders y optimizador\n",
    "batch_size = BATCH_SIZE\n",
    "dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=1e-8)\n",
    "epochs = EPOCH\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train)*epochs)\n",
    "\n",
    "# Definici√≥n de funciones para evaluaci√≥n y m√©tricas\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# C√°lculo de los pesos de clase\n",
    "class_wts = compute_class_weight(class_weight='balanced', classes=np.unique(labels_train), y=labels_train.numpy())\n",
    "weights = torch.tensor(class_wts, dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# Definici√≥n de la funci√≥n de p√©rdida con pesos de clase\n",
    "def weighted_cross_entropy(outputs, targets):\n",
    "    return torch.nn.CrossEntropyLoss(weight=weights)(outputs, targets)\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1]\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = weighted_cross_entropy(outputs, batch[2])\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        # Append predictions and true values for later evaluation\n",
    "        predictions.append(outputs.detach().cpu().numpy())\n",
    "        true_vals.append(batch[2].cpu().numpy())\n",
    "\n",
    "    # Calculate average loss over all batches\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "\n",
    "    # Concatenate all batches\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    # Convert predictions to labels\n",
    "    preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "\n",
    "    \"\"\"\n",
    "    # Calcular la matriz de confusi√≥n\n",
    "    cm = confusion_matrix(true_vals.flatten(), preds_flat)\n",
    "\n",
    "    # Opcional: Visualizar la matriz de confusi√≥n\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=\"Blues\")\n",
    "    ax.set_xlabel('Predicciones')\n",
    "    ax.set_ylabel('Etiquetas Verdaderas')\n",
    "    ax.set_title('Matriz de Confusi√≥n')\n",
    "    plt.show()\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Retorna la p√©rdida promedio, predicciones, etiquetas verdaderas, y la matriz de confusi√≥n\n",
    "    return loss_val_avg, predictions, true_vals #, cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [02:33<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 1.0858481047731456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 1/10 [03:06<27:55, 186.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.0648702039863125\n",
      "F1 Score (Weighted): 0.4595550894325579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 1/10 [05:44<27:55, 186.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 1.0687067206158782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 2/10 [06:18<25:17, 189.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.0427581884644248\n",
      "F1 Score (Weighted): 0.6663276117821573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 2/10 [08:52<25:17, 189.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 1.061719097422831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 3/10 [09:27<22:05, 189.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.03053926337849\n",
      "F1 Score (Weighted): 0.6986958816662909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 3/10 [12:06<22:05, 189.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 1.0472332510081204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [12:39<19:03, 190.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.0221271966442917\n",
      "F1 Score (Weighted): 0.6863400755173675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [15:23<19:03, 190.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 1.0352042601867155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [15:55<16:02, 192.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.0158829725149907\n",
      "F1 Score (Weighted): 0.6817896294610283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [18:39<16:02, 192.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6\n",
      "Training loss: 1.0355048102862907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [19:13<12:57, 194.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.0100330836845166\n",
      "F1 Score (Weighted): 0.6786081690042677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [22:14<12:57, 194.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7\n",
      "Training loss: 1.0361814065413042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [22:46<10:01, 200.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.0042232907179631\n",
      "F1 Score (Weighted): 0.697296279931648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [25:31<10:01, 200.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8\n",
      "Training loss: 1.0238399961681077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [26:06<06:40, 200.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.0012055274212\n",
      "F1 Score (Weighted): 0.700249043106186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [39:56<06:40, 200.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9\n",
      "Training loss: 1.02882772322857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [41:29<07:06, 426.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.999875337788553\n",
      "F1 Score (Weighted): 0.698698059469028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [1:04:57<07:13, 433.04s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     14\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: batch[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: batch[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     17\u001b[0m }\n\u001b[1;32m---> 19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#logits = outputs.logits\u001b[39;00m\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m weighted_cross_entropy(outputs, batch[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[5], line 73\u001b[0m, in \u001b[0;36mROBERTAClass.forward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[1;32m---> 73\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m# Use the pooled output (the second element of the outputs tuple) for classification\u001b[39;00m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# This is typically what you want for a classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     pooler_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1012\u001b[0m )\n\u001b[1;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    598\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m         output_attentions,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:436\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[0;32m    428\u001b[0m         hidden_states,\n\u001b[0;32m    429\u001b[0m         attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    434\u001b[0m         output_attentions,\n\u001b[0;32m    435\u001b[0m     )\n\u001b[1;32m--> 436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    386\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m    387\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m--> 388\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1494\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1491\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[0;32m   1492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1495\u001b[0m     forward_call \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward)\n\u001b[0;32m   1496\u001b[0m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        # Reset the gradients from the previous iteration\n",
    "        model.zero_grad()\n",
    "\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1]\n",
    "        }\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        #logits = outputs.logits\n",
    "        loss = weighted_cross_entropy(outputs, batch[2])\n",
    "        loss_train_total += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "\n",
    "    # -------------------------- comentado por el momento para no ocupar espacio en disco -------------------------------------------\n",
    "    #torch.save(model.state_dict(), f'roberta-base-bne/finetuned_roberta-base-bne_epoch_{epoch}.model')\n",
    "\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    #val_loss, predictions, true_vals, confusion_matrix = evaluate(dataloader_validation)\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluaci√≥n del modelo en el conjunto de validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluaci√≥n en el conjunto de validaci√≥n\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "\n",
    "# Manipulaci√≥n de predicciones y creaci√≥n del csv\n",
    "tensor_pred = torch.from_numpy(predictions)\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "softmax(tensor_pred)\n",
    "df_predictions = pd.DataFrame(columns = [\"full_text_processed\", \"True Rating\", \"Predicted Rating\", \"Pred Prob 0\", \"Pred Prob 1\", \"Pred Prob 2\"])\n",
    "df_predictions[\"full_text_processed\"] = df[df.data_type=='val']['full_text_processed'].copy().reset_index(drop = True)\n",
    "df_predictions[\"True Rating\"] = df[df.data_type=='val']['label'].reset_index(drop = True).copy()\n",
    "df_predictions[\"Predicted Rating\"] = np.argmax(predictions, axis=1)\n",
    "df_predictions[[\"Pred Prob 0\", \"Pred Prob 1\", \"Pred Prob 2\"]] = list(softmax(tensor_pred).numpy())\n",
    "df_predictions.to_csv('df_predictions.csv', encoding = 'utf8')\n",
    "df_predictions.to_excel('df_prediction.xlsx')\n",
    "val_f1 = f1_score_func(predictions, true_vals)\n",
    "acc = accuracy_per_class(predictions, true_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
